{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Building Tree-Based Models in Practice\n\n## Course 3: Advanced Classification Models for Student Success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n\nIn this notebook, we apply the **instantiate \u2192 fit \u2192 predict** pattern to build all three tree-based models on our student departure dataset. The emphasis is on the **practical workflow**\u2014you'll see how little changes between models.\n\n### Learning Objectives\n\nBy the end of this notebook, you will be able to:\n\n1. Load and prepare data for tree-based models\n2. Build a Decision Tree, Random Forest, and XGBoost model using the same workflow\n3. Generate predictions and probability estimates\n4. Extract feature importances from each model\n5. Visualize a decision tree for stakeholder communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\n# Models \u2014 note: all from scikit-learn compatible API\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\n# Evaluation\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score,\n                              f1_score, roc_auc_score, classification_report)\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\n\nimport time\n\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\n\nprint(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\ntrain_df = pd.read_csv('../../data/training.csv')\ntest_df = pd.read_csv('../../data/testing.csv')\n\n# Create binary target\ntrain_df['DEPARTED'] = (train_df['SEM_3_STATUS'] != 'E').astype(int)\ntest_df['DEPARTED'] = (test_df['SEM_3_STATUS'] != 'E').astype(int)\n\nprint(f\"Training set: {train_df.shape[0]:,} students\")\nprint(f\"Testing set: {test_df.shape[0]:,} students\")\nprint(f\"Departure rate (Train): {train_df['DEPARTED'].mean():.2%}\")\nprint(f\"Departure rate (Test): {test_df['DEPARTED'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features \u2014 NO SCALING NEEDED for tree-based models!\nnumeric_features = [\n    'HS_GPA', 'HS_MATH_GPA', 'HS_ENGL_GPA',\n    'UNITS_ATTEMPTED_1', 'UNITS_ATTEMPTED_2',\n    'UNITS_COMPLETED_1', 'UNITS_COMPLETED_2',\n    'DFW_UNITS_1', 'DFW_UNITS_2',\n    'GPA_1', 'GPA_2',\n    'DFW_RATE_1', 'DFW_RATE_2',\n    'GRADE_POINTS_1', 'GRADE_POINTS_2'\n]\n\ncategorical_features = ['RACE_ETHNICITY', 'GENDER', 'FIRST_GEN_STATUS', 'COLLEGE']\ntarget = 'DEPARTED'\n\n# One-hot encode categorical variables\ntrain_encoded = pd.get_dummies(train_df[numeric_features + categorical_features],\n                               columns=categorical_features, drop_first=True)\ntest_encoded = pd.get_dummies(test_df[numeric_features + categorical_features],\n                              columns=categorical_features, drop_first=True)\n\n# Align columns\ntrain_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n\n# Handle missing values\ntrain_encoded = train_encoded.fillna(train_encoded.median())\ntest_encoded = test_encoded.fillna(test_encoded.median())\n\nX_train = train_encoded\ny_train = train_df[target]\nX_test = test_encoded\ny_test = test_df[target]\n\nprint(f\"Features: {X_train.shape[1]}\")\nprint(f\"\\nKey advantage: No feature scaling needed for tree-based models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Three Models: Same Pattern, Different Strengths\n\nWatch how the code structure is nearly identical for all three models. The only difference is the class name and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model 1: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DECISION TREE ===\n# Step 1: Instantiate\ndt = DecisionTreeClassifier(\n    max_depth=8,\n    min_samples_split=20,\n    min_samples_leaf=10,\n    max_features='sqrt',\n    class_weight='balanced',\n    random_state=RANDOM_STATE\n)\n\n# Step 2: Fit\nstart = time.time()\ndt.fit(X_train, y_train)\ndt_time = time.time() - start\n\n# Step 3: Predict\ndt_pred = dt.predict(X_test)\ndt_prob = dt.predict_proba(X_test)[:, 1]\n\n# Step 4: Evaluate\nprint(\"=== Decision Tree Results ===\")\nprint(f\"Training time: {dt_time:.3f}s\")\nprint(f\"Accuracy:  {accuracy_score(y_test, dt_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, dt_pred):.4f}\")\nprint(f\"Recall:    {recall_score(y_test, dt_pred):.4f}\")\nprint(f\"F1 Score:  {f1_score(y_test, dt_pred):.4f}\")\nprint(f\"ROC-AUC:   {roc_auc_score(y_test, dt_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANDOM FOREST ===\n# Step 1: Instantiate\nrf = RandomForestClassifier(\n    n_estimators=200,\n    max_depth=12,\n    min_samples_split=10,\n    min_samples_leaf=5,\n    max_features='sqrt',\n    class_weight='balanced',\n    n_jobs=-1,\n    random_state=RANDOM_STATE\n)\n\n# Step 2: Fit\nstart = time.time()\nrf.fit(X_train, y_train)\nrf_time = time.time() - start\n\n# Step 3: Predict\nrf_pred = rf.predict(X_test)\nrf_prob = rf.predict_proba(X_test)[:, 1]\n\n# Step 4: Evaluate\nprint(\"=== Random Forest Results ===\")\nprint(f\"Training time: {rf_time:.3f}s\")\nprint(f\"Accuracy:  {accuracy_score(y_test, rf_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, rf_pred):.4f}\")\nprint(f\"Recall:    {recall_score(y_test, rf_pred):.4f}\")\nprint(f\"F1 Score:  {f1_score(y_test, rf_pred):.4f}\")\nprint(f\"ROC-AUC:   {roc_auc_score(y_test, rf_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === XGBOOST ===\n# Step 1: Instantiate\nxgb = XGBClassifier(\n    n_estimators=150,\n    learning_rate=0.1,\n    max_depth=5,\n    min_child_weight=3,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),\n    use_label_encoder=False,\n    eval_metric='logloss',\n    random_state=RANDOM_STATE\n)\n\n# Step 2: Fit\nstart = time.time()\nxgb.fit(X_train, y_train)\nxgb_time = time.time() - start\n\n# Step 3: Predict\nxgb_pred = xgb.predict(X_test)\nxgb_prob = xgb.predict_proba(X_test)[:, 1]\n\n# Step 4: Evaluate\nprint(\"=== XGBoost Results ===\")\nprint(f\"Training time: {xgb_time:.3f}s\")\nprint(f\"Accuracy:  {accuracy_score(y_test, xgb_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, xgb_pred):.4f}\")\nprint(f\"Recall:    {recall_score(y_test, xgb_pred):.4f}\")\nprint(f\"F1 Score:  {f1_score(y_test, xgb_pred):.4f}\")\nprint(f\"ROC-AUC:   {roc_auc_score(y_test, xgb_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Side-by-Side Comparison\n\nNow let's see how the three models compare directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\nresults = pd.DataFrame({\n    'Model': ['Decision Tree', 'Random Forest', 'XGBoost'],\n    'Accuracy': [accuracy_score(y_test, p) for p in [dt_pred, rf_pred, xgb_pred]],\n    'Precision': [precision_score(y_test, p) for p in [dt_pred, rf_pred, xgb_pred]],\n    'Recall': [recall_score(y_test, p) for p in [dt_pred, rf_pred, xgb_pred]],\n    'F1 Score': [f1_score(y_test, p) for p in [dt_pred, rf_pred, xgb_pred]],\n    'ROC-AUC': [roc_auc_score(y_test, p) for p in [dt_prob, rf_prob, xgb_prob]],\n    'Train Time (s)': [dt_time, rf_time, xgb_time]\n})\n\nprint(\"=\" * 80)\nprint(\"TREE-BASED MODELS: HEAD-TO-HEAD COMPARISON\")\nprint(\"=\" * 80)\nprint(results.to_string(index=False))\nprint(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison\nfig = go.Figure()\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\ncolors = ['#2ecc71', '#3498db', '#e74c3c']\n\nfor i, model in enumerate(results['Model']):\n    fig.add_trace(go.Bar(\n        name=model,\n        x=metrics,\n        y=[results.loc[i, m] for m in metrics],\n        marker_color=colors[i]\n    ))\n\nfig.update_layout(\n    title='Tree-Based Models: Performance Comparison',\n    yaxis_title='Score', barmode='group', height=450,\n    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1)\n)\nfig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance\n\nAll three tree-based models provide **feature importance scores**\u2014another shared capability. Feature importance tells us which student characteristics are most predictive of departure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances from all three models\nimportance_df = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Decision Tree': dt.feature_importances_,\n    'Random Forest': rf.feature_importances_,\n    'XGBoost': xgb.feature_importances_\n})\n\n# Sort by Random Forest importance (usually most stable)\nimportance_df = importance_df.sort_values('Random Forest', ascending=False).head(15)\n\n# Plot\nfig = make_subplots(rows=1, cols=3, subplot_titles=('Decision Tree', 'Random Forest', 'XGBoost'))\n\nfor col, model in enumerate(['Decision Tree', 'Random Forest', 'XGBoost'], 1):\n    sorted_df = importance_df.sort_values(model, ascending=True)\n    fig.add_trace(go.Bar(\n        y=sorted_df['Feature'], x=sorted_df[model],\n        orientation='h', marker_color=colors[col-1], showlegend=False\n    ), row=1, col=col)\n\nfig.update_layout(height=500, title_text='Top 15 Features by Importance (All Three Models)')\nfig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizing the Decision Tree\n\nOne of the biggest advantages of Decision Trees is that we can **visualize the entire model**. This is invaluable for communicating with non-technical stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n\n# Train a shallow tree for visualization\ndt_visual = DecisionTreeClassifier(max_depth=3, class_weight='balanced', random_state=42)\ndt_visual.fit(X_train, y_train)\n\nfig, ax = plt.subplots(figsize=(20, 10))\nplot_tree(dt_visual, feature_names=X_train.columns, class_names=['Enrolled', 'Departed'],\n          filled=True, rounded=True, fontsize=10, ax=ax)\nplt.title('Decision Tree for Student Departure Prediction (max_depth=3)', fontsize=16)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nThis tree can be directly shared with academic advisors!\")\nprint(\"Each path from root to leaf is an interpretable rule.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation: More Robust Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation for all three models\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\nmodels_cv = {\n    'Decision Tree': DecisionTreeClassifier(max_depth=8, min_samples_split=20,\n                                             min_samples_leaf=10, class_weight='balanced',\n                                             random_state=RANDOM_STATE),\n    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=12,\n                                             min_samples_leaf=5, class_weight='balanced',\n                                             n_jobs=-1, random_state=RANDOM_STATE),\n    'XGBoost': XGBClassifier(n_estimators=150, learning_rate=0.1, max_depth=5,\n                              subsample=0.8, colsample_bytree=0.8,\n                              use_label_encoder=False, eval_metric='logloss',\n                              random_state=RANDOM_STATE)\n}\n\nprint(\"5-Fold Cross-Validation Results (ROC-AUC):\")\nprint(\"-\" * 50)\nfor name, model in models_cv.items():\n    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n    print(f\"{name:20s}: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n\n### What We Learned\n\n1. **Same workflow, three models**: `instantiate \u2192 fit \u2192 predict` works identically for all three\n2. **No preprocessing needed**: Tree-based models handle raw features (no scaling required)\n3. **Feature importances**: All three provide built-in feature importance scores\n4. **Decision Trees are visualizable**: Perfect for stakeholder communication\n5. **Random Forests are robust**: Good default choice with minimal tuning\n6. **XGBoost often wins on performance**: Best for when accuracy matters most\n\n### The Practical Takeaway\n\n```python\n# Switching between models is this easy:\nmodel = DecisionTreeClassifier(max_depth=8)    # Option A\nmodel = RandomForestClassifier(n_estimators=200) # Option B\nmodel = XGBClassifier(n_estimators=150)          # Option C\n\n# Everything else stays the same!\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\nprobabilities = model.predict_proba(X_test)[:, 1]\n```\n\n### Next Steps\n\nIn the next notebook, we'll dive into **hyperparameter tuning** for each model and learn strategies to get the best performance.\n\n**Proceed to:** `2.3 Tuning Tree-Based Models`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}