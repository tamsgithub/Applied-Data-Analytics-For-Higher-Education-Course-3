{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Code Brief: Train and Compare Regularized Models\n",
    "\n",
    "Quick reference for training and comparing regularized logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filepath = '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/'\n",
    "data_filepath = f'{root_filepath}data/'\n",
    "course3_models = f'{root_filepath}course_3/models/'\n",
    "\n",
    "df_training = pd.read_csv(f'{data_filepath}training.csv')\n",
    "X_train = df_training\n",
    "y_train = df_training['SEM_3_STATUS']\n",
    "\n",
    "l2_model = pickle.load(open(f'{course3_models}l2_ridge_logistic_model.pkl', 'rb'))\n",
    "l1_model = pickle.load(open(f'{course3_models}l1_lasso_logistic_model.pkl', 'rb'))\n",
    "elasticnet_model = pickle.load(open(f'{course3_models}elasticnet_logistic_model.pkl', 'rb'))\n",
    "\n",
    "models = {\n",
    "    'L2 (Ridge)': l2_model,\n",
    "    'L1 (Lasso)': l1_model,\n",
    "    'ElasticNet': elasticnet_model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = trained_models['L2 (Ridge)'].named_steps['preprocessing']\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "feature_names_clean = [name.split('__')[-1] for name in feature_names]\n",
    "\n",
    "coef_data = []\n",
    "for name, model in trained_models.items():\n",
    "    classifier = model.named_steps['classifier']\n",
    "    for feat, coef in zip(feature_names_clean, classifier.coef_[0]):\n",
    "        coef_data.append({'Model': name, 'Feature': feat, 'Coefficient': coef})\n",
    "\n",
    "coef_df = pd.DataFrame(coef_data)\n",
    "fig = px.bar(coef_df, x='Feature', y='Coefficient', color='Model', barmode='group',\n",
    "             title='Coefficient Comparison Across Regularization Types', height=500)\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_classifier = trained_models['L1 (Lasso)'].named_steps['classifier']\n",
    "l1_coefficients = l1_classifier.coef_[0]\n",
    "\n",
    "l1_selection = pd.DataFrame({\n",
    "    'Feature': feature_names_clean,\n",
    "    'Coefficient': l1_coefficients,\n",
    "    'Selected': l1_coefficients != 0\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(f\"Total features: {len(l1_selection)}\")\n",
    "print(f\"Selected (non-zero): {l1_selection['Selected'].sum()}\")\n",
    "print(f\"Eliminated (zero): {(~l1_selection['Selected']).sum()}\")\n",
    "display(l1_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score, pos_label='N')\n",
    "precision_scorer = make_scorer(precision_score, pos_label='N')\n",
    "recall_scorer = make_scorer(recall_score, pos_label='N')\n",
    "\n",
    "cv_results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"Cross-validating {name}...\")\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=f1_scorer)\n",
    "    precision_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=precision_scorer)\n",
    "    recall_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=recall_scorer)\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'F1 Mean': f1_scores.mean(),\n",
    "        'Precision Mean': precision_scores.mean(),\n",
    "        'Recall Mean': recall_scores.mean()\n",
    "    })\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "display(cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in trained_models.items():\n",
    "    filename = name.lower().replace(' ', '_').replace('(', '').replace(')', '')\n",
    "    filepath = f'{course3_models}{filename}_trained.pkl'\n",
    "    pickle.dump(model, open(filepath, 'wb'))\n",
    "    print(f\"Saved: {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
