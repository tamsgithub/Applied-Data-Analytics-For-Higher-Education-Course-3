{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Code Brief: Introduction to Regularization\n",
    "\n",
    "Quick reference for regularization concepts and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 20)\n",
    "y_true = 2 * X + 1\n",
    "y_noisy = y_true + np.random.normal(0, 3, len(X))\n",
    "\n",
    "X_smooth = np.linspace(0, 10, 100)\n",
    "y_underfit = np.ones_like(X_smooth) * np.mean(y_noisy)\n",
    "y_goodfit = np.polyval(np.polyfit(X, y_noisy, 1), X_smooth)\n",
    "y_overfit = np.polyval(np.polyfit(X, y_noisy, 15), X_smooth)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=3, subplot_titles=('Underfitting', 'Good Fit', 'Overfitting'))\n",
    "for col in [1, 2, 3]:\n",
    "    fig.add_trace(go.Scatter(x=X, y=y_noisy, mode='markers', marker=dict(color='blue', size=8), showlegend=(col==1), name='Data'), row=1, col=col)\n",
    "fig.add_trace(go.Scatter(x=X_smooth, y=y_underfit, mode='lines', line=dict(color='red', width=2), showlegend=False), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=X_smooth, y=y_goodfit, mode='lines', line=dict(color='green', width=2), showlegend=False), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=X_smooth, y=y_overfit, mode='lines', line=dict(color='red', width=2), showlegend=False), row=1, col=3)\n",
    "fig.update_layout(height=400, title_text=\"The Fitting Spectrum\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity = np.linspace(0.1, 3, 100)\n",
    "bias_squared = 1 / complexity\n",
    "variance = 0.3 * complexity ** 2\n",
    "total_error = bias_squared + variance + 0.1\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=complexity, y=bias_squared, mode='lines', name='Bias²', line=dict(color='blue', width=2)))\n",
    "fig.add_trace(go.Scatter(x=complexity, y=variance, mode='lines', name='Variance', line=dict(color='orange', width=2)))\n",
    "fig.add_trace(go.Scatter(x=complexity, y=total_error, mode='lines', name='Total Error', line=dict(color='red', width=3)))\n",
    "optimal_idx = np.argmin(total_error)\n",
    "fig.add_vline(x=complexity[optimal_idx], line_dash=\"dash\", line_color=\"green\", annotation_text=\"Optimal\")\n",
    "fig.update_layout(title='Bias-Variance Trade-off', xaxis_title='Model Complexity', yaxis_title='Error', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 vs L2 Regularization Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "x_l2 = np.cos(theta)\n",
    "y_l2 = np.sin(theta)\n",
    "\n",
    "t = np.linspace(0, 1, 25)\n",
    "x_l1 = np.concatenate([1-t, -t, -1+t, t])\n",
    "y_l1 = np.concatenate([t, 1-t, -t, -1+t])\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('L2 (Ridge) Constraint', 'L1 (Lasso) Constraint'))\n",
    "fig.add_trace(go.Scatter(x=x_l2, y=y_l2, mode='lines', fill='toself', fillcolor='rgba(0,100,200,0.3)', line=dict(color='blue', width=2)), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=x_l1, y=y_l1, mode='lines', fill='toself', fillcolor='rgba(200,100,0,0.3)', line=dict(color='orange', width=2)), row=1, col=2)\n",
    "fig.update_layout(height=400, title_text=\"Geometry of Regularization\", showlegend=False)\n",
    "fig.update_xaxes(title_text=\"β₁\", range=[-1.5, 1.5])\n",
    "fig.update_yaxes(title_text=\"β₂\", range=[-1.5, 1.5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "| Type | Penalty | Feature Selection | Best For |\n",
    "|:-----|:--------|:------------------|:---------|\n",
    "| L2 (Ridge) | Sum of squared coefficients | No | Many small effects |\n",
    "| L1 (Lasso) | Sum of absolute coefficients | Yes | Few large effects |\n",
    "| ElasticNet | Both | Yes | Correlated features |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
