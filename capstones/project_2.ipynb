{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project 2: Equity Analysis - Model Performance by Student Subgroups\n",
    "\n",
    "## Objective\n",
    "This notebook walks you through the UPAD cycle (Understand, Prepare, Analyze, Deploy) to:\n",
    "- Analyze model fairness across Race/Ethnicity, First Generation Status, and Gender\n",
    "- Build and compare best-performing models for each demographic subgroup\n",
    "- Compare performance metrics across groups to identify potential bias\n",
    "- Discuss fairness implications and develop higher education policy recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Equity in Predictive Analytics\n",
    "\n",
    "As universities increasingly adopt machine learning models for student success initiatives, it is critical to ensure these models do not perpetuate or amplify existing inequities. A model that performs well on average may still produce systematically different outcomes for different student populations.\n",
    "\n",
    "**Fairness concerns in higher education include:**\n",
    "- **Predictive parity**: Does the model predict with equal accuracy across groups?\n",
    "- **Error rate parity**: Are false positive and false negative rates similar across groups?\n",
    "- **Disparate impact**: Do model predictions lead to different intervention rates by group?\n",
    "\n",
    "This capstone project examines model performance across three key demographic dimensions:\n",
    "1. **Race/Ethnicity**: Ensuring the model works equally well for students of all racial/ethnic backgrounds\n",
    "2. **First Generation Status**: Checking if first-generation students are fairly served\n",
    "3. **Gender**: Verifying gender equity in model predictions\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this capstone, you will be able to:\n",
    "1. Evaluate model performance separately for demographic subgroups\n",
    "2. Identify potential sources of algorithmic bias\n",
    "3. Apply fairness metrics to machine learning models\n",
    "4. Develop policy recommendations for equitable model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1: Import Libraries and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# Set random seed\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_location = '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/data/'\n",
    "df = pd.read_csv(f'{data_location}student_academics_data.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2: Data Cleaning and Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address Rare Classes in RACE_ETHNICITY\n",
    "df['RACE_ETHNICITY'] = df['RACE_ETHNICITY'].replace(\n",
    "    ['Unknown', 'Native Hawaiian or Other Pacific Islander', 'American Indian or Alaska Native'], \n",
    "    'Other'\n",
    ")\n",
    "\n",
    "# Address Rare Classes in GENDER\n",
    "df = df[df['GENDER'] != 'Nonbinary']\n",
    "df['GENDER'] = df['GENDER'].str.strip().str.capitalize()\n",
    "\n",
    "# Drop noninformative features\n",
    "df.drop(['SEM_1_STATUS', 'SEM_2_STATUS'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop columns with >50% missing values\n",
    "missing_pct = df.isnull().sum() / len(df)\n",
    "cols_to_drop = missing_pct[missing_pct > 0.5].index.tolist()\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Create binary target\n",
    "df['DEPARTED'] = (df['SEM_3_STATUS'] != 'E').astype(int)\n",
    "\n",
    "print(f\"Cleaned dataset shape: {df.shape}\")\n",
    "print(f\"\\nDeparture rate: {df['DEPARTED'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 3: Examine Demographic Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display demographic distributions\n",
    "print(\"=\"*60)\n",
    "print(\"DEMOGRAPHIC DISTRIBUTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nRace/Ethnicity:\")\n",
    "print(df['RACE_ETHNICITY'].value_counts())\n",
    "\n",
    "print(\"\\nFirst Generation Status:\")\n",
    "print(df['FIRST_GEN_STATUS'].value_counts())\n",
    "\n",
    "print(\"\\nGender:\")\n",
    "print(df['GENDER'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize departure rates by demographic groups\n",
    "fig = make_subplots(rows=1, cols=3, \n",
    "                    subplot_titles=('By Race/Ethnicity', 'By First Gen Status', 'By Gender'))\n",
    "\n",
    "# Race/Ethnicity\n",
    "race_rates = df.groupby('RACE_ETHNICITY')['DEPARTED'].agg(['mean', 'count']).reset_index()\n",
    "race_rates.columns = ['Group', 'Departure Rate', 'N']\n",
    "race_rates = race_rates.sort_values('Departure Rate', ascending=False)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_rates['Group'], y=race_rates['Departure Rate'], \n",
    "           text=[f\"{r:.1%}<br>n={n:,}\" for r, n in zip(race_rates['Departure Rate'], race_rates['N'])],\n",
    "           textposition='outside', marker_color='steelblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# First Gen Status\n",
    "fg_rates = df.groupby('FIRST_GEN_STATUS')['DEPARTED'].agg(['mean', 'count']).reset_index()\n",
    "fg_rates.columns = ['Group', 'Departure Rate', 'N']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=fg_rates['Group'], y=fg_rates['Departure Rate'],\n",
    "           text=[f\"{r:.1%}<br>n={n:,}\" for r, n in zip(fg_rates['Departure Rate'], fg_rates['N'])],\n",
    "           textposition='outside', marker_color='coral'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Gender\n",
    "gender_rates = df.groupby('GENDER')['DEPARTED'].agg(['mean', 'count']).reset_index()\n",
    "gender_rates.columns = ['Group', 'Departure Rate', 'N']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=gender_rates['Group'], y=gender_rates['Departure Rate'],\n",
    "           text=[f\"{r:.1%}<br>n={n:,}\" for r, n in zip(gender_rates['Departure Rate'], gender_rates['N'])],\n",
    "           textposition='outside', marker_color='forestgreen'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Departure Rates by Demographic Group',\n",
    "    height=450,\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "fig.update_yaxes(tickformat='.0%')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 4: Prepare Features and Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['DFW_RATE_1'] = ((df['UNITS_ATTEMPTED_1'] - df['UNITS_COMPLETED_1']).clip(lower=0) \n",
    "                        / df['UNITS_ATTEMPTED_1'].replace(0, 1))\n",
    "    df['DFW_RATE_2'] = ((df['UNITS_ATTEMPTED_2'] - df['UNITS_COMPLETED_2']).clip(lower=0) \n",
    "                        / df['UNITS_ATTEMPTED_2'].replace(0, 1))\n",
    "    df['GRADE_POINTS_1'] = df['UNITS_ATTEMPTED_1'] * df['GPA_1']\n",
    "    df['GRADE_POINTS_2'] = df['UNITS_ATTEMPTED_2'] * df['GPA_2']\n",
    "    return df\n",
    "\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "numeric_features = [\n",
    "    'HS_GPA', 'HS_MATH_GPA', 'HS_ENGL_GPA',\n",
    "    'UNITS_ATTEMPTED_1', 'UNITS_ATTEMPTED_2',\n",
    "    'UNITS_COMPLETED_1', 'UNITS_COMPLETED_2',\n",
    "    'DFW_UNITS_1', 'DFW_UNITS_2',\n",
    "    'GPA_1', 'GPA_2',\n",
    "    'DFW_RATE_1', 'DFW_RATE_2',\n",
    "    'GRADE_POINTS_1', 'GRADE_POINTS_2'\n",
    "]\n",
    "\n",
    "categorical_features = ['COLLEGE']  # Note: We exclude demographic features from model inputs\n",
    "\n",
    "# Store demographic columns for later analysis\n",
    "demographic_cols = ['RACE_ETHNICITY', 'FIRST_GEN_STATUS', 'GENDER']\n",
    "\n",
    "target = 'DEPARTED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "for col in numeric_features:\n",
    "    if df[col].isnull().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Train/Test split - maintain demographic information for fairness analysis\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE, stratify=df['DEPARTED'])\n",
    "\n",
    "print(f\"Training set: {len(train_df):,} students\")\n",
    "print(f\"Testing set: {len(test_df):,} students\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature matrices\n",
    "train_encoded = pd.get_dummies(train_df[numeric_features + categorical_features], \n",
    "                               columns=categorical_features, drop_first=True)\n",
    "test_encoded = pd.get_dummies(test_df[numeric_features + categorical_features], \n",
    "                              columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Fill any remaining NaN\n",
    "train_encoded = train_encoded.fillna(train_encoded.median())\n",
    "test_encoded = test_encoded.fillna(test_encoded.median())\n",
    "\n",
    "X_train = train_encoded\n",
    "y_train = train_df[target]\n",
    "X_test = test_encoded\n",
    "y_test = test_df[target]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Train the Best Model\n",
    "\n",
    "First, we train a high-performing model on the full dataset, then analyze its performance across subgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 5: Train Best-Performing Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest (typically performs well and provides feature importance)\n",
    "print(\"Training Random Forest model...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=12,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\nOverall Model Performance:\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fairness Analysis by Subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 6: Define Fairness Metrics Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_subgroup_metrics(y_true, y_pred, y_prob, group_labels, group_name):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for each subgroup.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for group in group_labels.unique():\n",
    "        mask = group_labels == group\n",
    "        n = mask.sum()\n",
    "        \n",
    "        if n < 10:  # Skip groups with too few samples\n",
    "            continue\n",
    "            \n",
    "        y_true_group = y_true[mask]\n",
    "        y_pred_group = y_pred[mask]\n",
    "        y_prob_group = y_prob[mask]\n",
    "        \n",
    "        # Calculate confusion matrix components\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_group, y_pred_group, labels=[0, 1]).ravel()\n",
    "        \n",
    "        metrics = {\n",
    "            'Group': group,\n",
    "            'N': n,\n",
    "            'Base Rate': y_true_group.mean(),  # Actual departure rate\n",
    "            'Positive Rate': y_pred_group.mean(),  # Predicted departure rate\n",
    "            'Accuracy': accuracy_score(y_true_group, y_pred_group),\n",
    "            'Precision': precision_score(y_true_group, y_pred_group, zero_division=0),\n",
    "            'Recall': recall_score(y_true_group, y_pred_group, zero_division=0),\n",
    "            'F1 Score': f1_score(y_true_group, y_pred_group, zero_division=0),\n",
    "            'ROC-AUC': roc_auc_score(y_true_group, y_prob_group) if len(np.unique(y_true_group)) > 1 else np.nan,\n",
    "            'FPR': fp / (fp + tn) if (fp + tn) > 0 else 0,  # False Positive Rate\n",
    "            'FNR': fn / (fn + tp) if (fn + tp) > 0 else 0,  # False Negative Rate\n",
    "        }\n",
    "        results.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 7: Analyze Performance by Race/Ethnicity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set demographic labels\n",
    "test_race = test_df['RACE_ETHNICITY'].values\n",
    "\n",
    "# Calculate metrics by race/ethnicity\n",
    "race_metrics = calculate_subgroup_metrics(\n",
    "    y_test.values, y_pred, y_prob, \n",
    "    pd.Series(test_race), 'Race/Ethnicity'\n",
    ")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL PERFORMANCE BY RACE/ETHNICITY\")\n",
    "print(\"=\"*100)\n",
    "display_cols = ['Group', 'N', 'Base Rate', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC', 'FPR', 'FNR']\n",
    "print(race_metrics[display_cols].round(4).to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize racial equity metrics\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=('ROC-AUC by Race/Ethnicity', 'F1 Score by Race/Ethnicity',\n",
    "                                   'False Positive Rate by Race/Ethnicity', 'False Negative Rate by Race/Ethnicity'))\n",
    "\n",
    "race_metrics_sorted = race_metrics.sort_values('N', ascending=False)\n",
    "\n",
    "# ROC-AUC\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['ROC-AUC'], marker_color='steelblue'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# F1 Score\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['F1 Score'], marker_color='forestgreen'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# False Positive Rate\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['FPR'], marker_color='coral'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# False Negative Rate\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['FNR'], marker_color='purple'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=700, title_text=\"Equity Analysis: Model Performance by Race/Ethnicity\", showlegend=False)\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 8: Analyze Performance by First Generation Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set first gen labels\n",
    "test_firstgen = test_df['FIRST_GEN_STATUS'].values\n",
    "\n",
    "# Calculate metrics by first gen status\n",
    "fg_metrics = calculate_subgroup_metrics(\n",
    "    y_test.values, y_pred, y_prob, \n",
    "    pd.Series(test_firstgen), 'First Gen Status'\n",
    ")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL PERFORMANCE BY FIRST GENERATION STATUS\")\n",
    "print(\"=\"*100)\n",
    "print(fg_metrics[display_cols].round(4).to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first gen equity metrics\n",
    "fig = go.Figure()\n",
    "\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "colors = ['steelblue', 'coral', 'forestgreen', 'purple', 'orange']\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=metric,\n",
    "        x=fg_metrics['Group'],\n",
    "        y=fg_metrics[metric],\n",
    "        marker_color=colors[i]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Equity Analysis: Model Performance by First Generation Status',\n",
    "    barmode='group',\n",
    "    height=450,\n",
    "    legend=dict(orientation='h', y=1.1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 9: Analyze Performance by Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set gender labels\n",
    "test_gender = test_df['GENDER'].values\n",
    "\n",
    "# Calculate metrics by gender\n",
    "gender_metrics = calculate_subgroup_metrics(\n",
    "    y_test.values, y_pred, y_prob, \n",
    "    pd.Series(test_gender), 'Gender'\n",
    ")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MODEL PERFORMANCE BY GENDER\")\n",
    "print(\"=\"*100)\n",
    "print(gender_metrics[display_cols].round(4).to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gender equity metrics\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=metric,\n",
    "        x=gender_metrics['Group'],\n",
    "        y=gender_metrics[metric],\n",
    "        marker_color=colors[i]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Equity Analysis: Model Performance by Gender',\n",
    "    barmode='group',\n",
    "    height=400,\n",
    "    legend=dict(orientation='h', y=1.1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fairness Disparity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 10: Calculate Disparity Ratios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disparity_ratios(metrics_df, metric_name, reference_group=None):\n",
    "    \"\"\"\n",
    "    Calculate disparity ratios relative to a reference group.\n",
    "    A ratio of 1.0 indicates parity.\n",
    "    \"\"\"\n",
    "    if reference_group is None:\n",
    "        # Use group with largest N as reference\n",
    "        reference_group = metrics_df.loc[metrics_df['N'].idxmax(), 'Group']\n",
    "    \n",
    "    reference_value = metrics_df.loc[metrics_df['Group'] == reference_group, metric_name].values[0]\n",
    "    \n",
    "    disparity = metrics_df.copy()\n",
    "    disparity[f'{metric_name} Ratio'] = disparity[metric_name] / reference_value\n",
    "    \n",
    "    return disparity[['Group', 'N', metric_name, f'{metric_name} Ratio']], reference_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate disparity ratios for key metrics\n",
    "print(\"=\"*80)\n",
    "print(\"FAIRNESS DISPARITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ROC-AUC disparity by race\n",
    "auc_disparity, ref = calculate_disparity_ratios(race_metrics, 'ROC-AUC')\n",
    "print(f\"\\nROC-AUC Disparity by Race/Ethnicity (Reference: {ref})\")\n",
    "print(auc_disparity.round(4).to_string(index=False))\n",
    "\n",
    "# FPR disparity by race (lower is better, so we want ratios close to 1)\n",
    "fpr_disparity, ref = calculate_disparity_ratios(race_metrics, 'FPR')\n",
    "print(f\"\\nFalse Positive Rate Disparity by Race/Ethnicity (Reference: {ref})\")\n",
    "print(fpr_disparity.round(4).to_string(index=False))\n",
    "\n",
    "# FNR disparity by race\n",
    "fnr_disparity, ref = calculate_disparity_ratios(race_metrics, 'FNR')\n",
    "print(f\"\\nFalse Negative Rate Disparity by Race/Ethnicity (Reference: {ref})\")\n",
    "print(fnr_disparity.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 11: Visualize Comprehensive Fairness Dashboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive fairness dashboard\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'ROC-AUC by Race/Ethnicity', 'Error Rates by Race/Ethnicity',\n",
    "        'ROC-AUC by First Gen Status', 'Error Rates by First Gen Status',\n",
    "        'ROC-AUC by Gender', 'Error Rates by Gender'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Race/Ethnicity ROC-AUC\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['ROC-AUC'], \n",
    "           marker_color='steelblue', name='ROC-AUC'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Race/Ethnicity Error Rates\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['FPR'], \n",
    "           name='FPR', marker_color='coral'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=race_metrics_sorted['Group'], y=race_metrics_sorted['FNR'], \n",
    "           name='FNR', marker_color='purple'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# First Gen ROC-AUC\n",
    "fig.add_trace(\n",
    "    go.Bar(x=fg_metrics['Group'], y=fg_metrics['ROC-AUC'], \n",
    "           marker_color='steelblue', showlegend=False),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# First Gen Error Rates\n",
    "fig.add_trace(\n",
    "    go.Bar(x=fg_metrics['Group'], y=fg_metrics['FPR'], \n",
    "           marker_color='coral', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=fg_metrics['Group'], y=fg_metrics['FNR'], \n",
    "           marker_color='purple', showlegend=False),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Gender ROC-AUC\n",
    "fig.add_trace(\n",
    "    go.Bar(x=gender_metrics['Group'], y=gender_metrics['ROC-AUC'], \n",
    "           marker_color='steelblue', showlegend=False),\n",
    "    row=3, col=1\n",
    ")\n",
    "\n",
    "# Gender Error Rates\n",
    "fig.add_trace(\n",
    "    go.Bar(x=gender_metrics['Group'], y=gender_metrics['FPR'], \n",
    "           marker_color='coral', showlegend=False),\n",
    "    row=3, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=gender_metrics['Group'], y=gender_metrics['FNR'], \n",
    "           marker_color='purple', showlegend=False),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    title_text=\"Comprehensive Fairness Dashboard: Model Performance Across Demographics\",\n",
    "    barmode='group'\n",
    ")\n",
    "fig.update_xaxes(tickangle=-45)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Subgroup-Specific Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 12: Train Separate Models for Key Subgroups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_subgroup_model(train_df, test_df, subgroup_col, subgroup_val, X_cols, target):\n",
    "    \"\"\"\n",
    "    Train a model specifically for a demographic subgroup.\n",
    "    \"\"\"\n",
    "    # Filter to subgroup\n",
    "    train_sub = train_df[train_df[subgroup_col] == subgroup_val].copy()\n",
    "    test_sub = test_df[test_df[subgroup_col] == subgroup_val].copy()\n",
    "    \n",
    "    if len(train_sub) < 100 or len(test_sub) < 20:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Prepare features\n",
    "    X_train_sub = train_sub[X_cols].fillna(train_sub[X_cols].median())\n",
    "    y_train_sub = train_sub[target]\n",
    "    X_test_sub = test_sub[X_cols].fillna(train_sub[X_cols].median())\n",
    "    y_test_sub = test_sub[target]\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_sub = model.predict(X_test_sub)\n",
    "    y_prob_sub = model.predict_proba(X_test_sub)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'Subgroup': subgroup_val,\n",
    "        'N_train': len(train_sub),\n",
    "        'N_test': len(test_sub),\n",
    "        'Accuracy': accuracy_score(y_test_sub, y_pred_sub),\n",
    "        'F1 Score': f1_score(y_test_sub, y_pred_sub),\n",
    "        'ROC-AUC': roc_auc_score(y_test_sub, y_prob_sub) if len(np.unique(y_test_sub)) > 1 else np.nan\n",
    "    }\n",
    "    \n",
    "    return model, metrics, (y_test_sub, y_pred_sub, y_prob_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for first gen vs continuing gen\n",
    "print(\"Training subgroup-specific models...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_cols = numeric_features\n",
    "subgroup_results = []\n",
    "\n",
    "for fg_status in ['First Generation', 'Continuing Generation']:\n",
    "    model, metrics, _ = train_subgroup_model(\n",
    "        train_df, test_df, 'FIRST_GEN_STATUS', fg_status, X_cols, target\n",
    "    )\n",
    "    if metrics:\n",
    "        subgroup_results.append(metrics)\n",
    "        print(f\"\\n{fg_status}:\")\n",
    "        print(f\"  Training samples: {metrics['N_train']:,}\")\n",
    "        print(f\"  Test samples: {metrics['N_test']:,}\")\n",
    "        print(f\"  ROC-AUC: {metrics['ROC-AUC']:.4f}\")\n",
    "        print(f\"  F1 Score: {metrics['F1 Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare subgroup-specific models vs global model\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: SUBGROUP MODELS vs GLOBAL MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for fg_status in ['First Generation', 'Continuing Generation']:\n",
    "    # Get subgroup-specific model performance\n",
    "    subgroup_metrics = next((m for m in subgroup_results if m['Subgroup'] == fg_status), None)\n",
    "    \n",
    "    # Get global model performance on this subgroup\n",
    "    global_metrics = fg_metrics[fg_metrics['Group'] == fg_status].iloc[0] if len(fg_metrics[fg_metrics['Group'] == fg_status]) > 0 else None\n",
    "    \n",
    "    if subgroup_metrics and global_metrics is not None:\n",
    "        comparison_data.append({\n",
    "            'Subgroup': fg_status,\n",
    "            'Global Model ROC-AUC': global_metrics['ROC-AUC'],\n",
    "            'Subgroup Model ROC-AUC': subgroup_metrics['ROC-AUC'],\n",
    "            'Improvement': subgroup_metrics['ROC-AUC'] - global_metrics['ROC-AUC']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 13: Generate Equity Report Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "race_auc_range = race_metrics['ROC-AUC'].max() - race_metrics['ROC-AUC'].min()\n",
    "race_fpr_range = race_metrics['FPR'].max() - race_metrics['FPR'].min()\n",
    "race_fnr_range = race_metrics['FNR'].max() - race_metrics['FNR'].min()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EQUITY ANALYSIS EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "OVERVIEW:\n",
    "This analysis examined model fairness across three demographic dimensions:\n",
    "- Race/Ethnicity ({len(race_metrics)} groups)\n",
    "- First Generation Status ({len(fg_metrics)} groups)\n",
    "- Gender ({len(gender_metrics)} groups)\n",
    "\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. RACE/ETHNICITY DISPARITIES:\n",
    "   - ROC-AUC range: {race_auc_range:.4f} (Max: {race_metrics['ROC-AUC'].max():.4f}, Min: {race_metrics['ROC-AUC'].min():.4f})\n",
    "   - False Positive Rate range: {race_fpr_range:.4f}\n",
    "   - False Negative Rate range: {race_fnr_range:.4f}\n",
    "   \n",
    "2. FIRST GENERATION STATUS:\n",
    "   - First Gen ROC-AUC: {fg_metrics[fg_metrics['Group']=='First Generation']['ROC-AUC'].values[0]:.4f if len(fg_metrics[fg_metrics['Group']=='First Generation']) > 0 else 'N/A'}\n",
    "   - Continuing Gen ROC-AUC: {fg_metrics[fg_metrics['Group']=='Continuing Generation']['ROC-AUC'].values[0]:.4f if len(fg_metrics[fg_metrics['Group']=='Continuing Generation']) > 0 else 'N/A'}\n",
    "\n",
    "3. GENDER:\n",
    "   - Female ROC-AUC: {gender_metrics[gender_metrics['Group']=='Female']['ROC-AUC'].values[0]:.4f if len(gender_metrics[gender_metrics['Group']=='Female']) > 0 else 'N/A'}\n",
    "   - Male ROC-AUC: {gender_metrics[gender_metrics['Group']=='Male']['ROC-AUC'].values[0]:.4f if len(gender_metrics[gender_metrics['Group']=='Male']) > 0 else 'N/A'}\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 14: Produce Comprehensive Policy Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable: Equity Analysis and Policy Recommendations Report\n",
    "\n",
    "Using the analyses above, write a comprehensive report that addresses the following:\n",
    "\n",
    "1. **Fairness Metrics Summary**: Create tables showing model performance metrics (Accuracy, Precision, Recall, F1, ROC-AUC, FPR, FNR) for each demographic subgroup. Identify which groups experience the best and worst model performance.\n",
    "\n",
    "2. **Disparity Analysis**: Calculate and interpret disparity ratios for key metrics. Are there statistically significant differences in model performance across groups? What are the practical implications?\n",
    "\n",
    "3. **Bias Identification**: Based on the error rate analysis (FPR and FNR), identify potential sources of algorithmic bias:\n",
    "   - Which groups are more likely to be incorrectly flagged as at-risk (false positives)?\n",
    "   - Which groups are more likely to be missed by the model (false negatives)?\n",
    "\n",
    "4. **Root Cause Analysis**: Discuss potential reasons for performance disparities:\n",
    "   - Training data representation\n",
    "   - Feature availability and quality\n",
    "   - Historical patterns in the data\n",
    "\n",
    "5. **Policy Recommendations**: Provide specific recommendations for:\n",
    "   - Model deployment considerations (should different thresholds be used for different groups?)\n",
    "   - Intervention design (how should resources be allocated across groups?)\n",
    "   - Monitoring and accountability (how should fairness be tracked over time?)\n",
    "   - Data collection improvements\n",
    "\n",
    "6. **Ethical Considerations**: Discuss the ethical implications of using predictive models for student success, including:\n",
    "   - Privacy concerns\n",
    "   - Potential for stigmatization\n",
    "   - Transparency and explainability\n",
    "   - Student agency and autonomy\n",
    "\n",
    "> **Rubric**: Your report should be 3-4 pages and include:\n",
    "> - Summary tables of performance metrics by demographic group\n",
    "> - At least 3 visualizations from your fairness analysis\n",
    "> - Specific, actionable policy recommendations\n",
    "> - Discussion of ethical considerations and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Your Report (Write Below)\n",
    "\n",
    "*[Write your comprehensive equity analysis and policy recommendations report here]*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
