{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 - Introduction to Course 3: Advanced Machine Learning for Higher Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Welcome to *Applied Data Analytics and Machine Learning - Course 3*, an advanced course developed by the **Institutional Research and Analytics Department, CSULB**.\n",
    "\n",
    "This course builds upon the foundational knowledge you gained in Course 2, where you learned to build, train, evaluate, and deploy classification and regression models using Logistic Regression and Linear Regression in scikit-learn. In Course 3, we expand your machine learning toolkit with more powerful and sophisticated algorithms.\n",
    "\n",
    "\n",
    "\n",
    "### Objective\n",
    "To understand the overall course design, learning objectives, and progression through advanced machine learning techniques for higher education analytics.\n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "This course assumes you have completed Course 2 and are comfortable with:\n",
    "- The machine learning cycle (Build, Train, Predict, Evaluate, Improve)\n",
    "- Data preprocessing and feature engineering\n",
    "- Model evaluation metrics (Accuracy, Precision, Recall, F1-Score, AUC)\n",
    "- Cross-validation and model selection\n",
    "- Python and scikit-learn fundamentals\n",
    "\n",
    "\n",
    ">Each notebook in this course is self-contained yet builds upon concepts from earlier modules. Completing them in sequence ensures conceptual continuity and practical readiness for subsequent modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Table of Contents**\n",
    "\n",
    "\n",
    "  - [1. Welcome and Course Purpose](#scrollTo=section1)\n",
    "  - [2. What You Will Learn](#scrollTo=section2)\n",
    "  - [3. Course Structure Overview](#scrollTo=section3)\n",
    "  - [4. The Evolution from Basic to Advanced Models](#scrollTo=section4)\n",
    "  - [5. Frequently Asked Questions (FAQ)](#scrollTo=section5)\n",
    "  - [6. Getting Started](#scrollTo=section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Welcome and Course Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Welcome back to your machine learning journey with the *Applied Data Analytics and Machine Learning* series from the **Institutional Research and Analytics Department, CSULB**. \n",
    "\n",
    "In Course 2, you mastered the fundamentals of supervised learning by building logistic regression and linear regression models to predict student outcomes. You learned to navigate the complete machine learning cycle—from data preparation through model deployment.\n",
    "\n",
    "Course 3 takes you deeper into the world of machine learning by introducing more sophisticated algorithms that often outperform the baseline models you've already built. These advanced techniques are widely used in both industry and research settings to tackle complex prediction problems.\n",
    "\n",
    "\n",
    "\n",
    "### Why Advanced Models Matter\n",
    "\n",
    "While logistic regression provides an excellent baseline and is highly interpretable, more complex models can:\n",
    "\n",
    "- **Capture non-linear relationships** that linear models cannot detect\n",
    "- **Handle feature interactions** automatically without manual feature engineering\n",
    "- **Improve predictive accuracy** on complex real-world problems\n",
    "- **Reduce overfitting** through regularization and ensemble techniques\n",
    "\n",
    "\n",
    "\n",
    "### Our Continued Focus: Student Success\n",
    "\n",
    "We will continue working with student departure prediction—the same problem you addressed in Course 2. This continuity allows you to:\n",
    "\n",
    "1. **Directly compare** how different algorithms perform on the same problem\n",
    "2. **Build intuition** for when to choose one model over another\n",
    "3. **Develop expertise** in a domain-specific application of machine learning\n",
    "\n",
    "\n",
    "\n",
    "### Learning Philosophy\n",
    "\n",
    "> *Understand the theory, master the practice, compare the results.*\n",
    "\n",
    "This course maintains the practice-first approach from Course 2 while introducing more theoretical foundations where necessary. You will not only learn how to implement advanced algorithms but also understand *why* they work and *when* to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What You Will Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This course progressively introduces advanced machine learning techniques, building from regularized linear models to tree-based ensembles and finally to neural networks.\n",
    "\n",
    "\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "Upon completing this course, learners will be able to:\n",
    "\n",
    "1. **Apply regularization techniques** (L1, L2, ElasticNet) to prevent overfitting and perform feature selection\n",
    "2. **Build and interpret decision tree models** for classification problems\n",
    "3. **Construct Random Forest ensembles** and understand the power of bagging\n",
    "4. **Implement gradient boosting algorithms** (XGBoost, LightGBM, CatBoost) for state-of-the-art performance\n",
    "5. **Design and train basic neural networks** using industry-standard frameworks\n",
    "6. **Compare and select models** systematically for real-world deployment\n",
    "7. **Apply advanced techniques** to higher education prediction problems through capstone projects\n",
    "\n",
    "\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "| Concept | Description |\n",
    "|:--------|:------------|\n",
    "| **Regularization** | Techniques to prevent overfitting by adding penalty terms to the loss function |\n",
    "| **Decision Trees** | Non-linear models that learn hierarchical decision rules from data |\n",
    "| **Ensemble Learning** | Combining multiple models to improve predictive performance |\n",
    "| **Bagging** | Bootstrap aggregating to reduce variance through parallel model training |\n",
    "| **Boosting** | Sequential model building where each model corrects predecessor errors |\n",
    "| **Neural Networks** | Layered architectures inspired by biological neurons for learning complex patterns |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Course Structure Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The course is organized into **seven instructional modules** followed by **capstone projects** that integrate all learned techniques.\n",
    "\n",
    "| Module | Title | Primary Focus |\n",
    "|:-------|:------|:--------------|\n",
    "| **0** | Course Introduction | Orientation and overview of advanced ML techniques |\n",
    "| **1** | Regularized Logistic Regression | L1 (Lasso), L2 (Ridge), and ElasticNet regularization |\n",
    "| **2** | Decision Trees | Tree-based classification and interpretability |\n",
    "| **3** | Random Forests | Ensemble learning through bagging |\n",
    "| **4** | Gradient Boosting | XGBoost, LightGBM, and CatBoost |\n",
    "| **5** | Neural Networks | Introduction to deep learning fundamentals |\n",
    "| **6** | Model Comparison & Selection | Systematic comparison and final model selection |\n",
    "| **Capstones** | Applied Projects | End-to-end projects using multiple techniques |\n",
    "\n",
    "\n",
    "\n",
    "### Module Progression\n",
    "\n",
    "The course follows a logical progression from simpler to more complex models:\n",
    "\n",
    "```\n",
    "Regularized Logistic Regression → Decision Trees → Random Forest → Gradient Boosting → Neural Networks\n",
    "        (Linear + Penalty)         (Non-linear)      (Bagging)        (Boosting)         (Deep Learning)\n",
    "```\n",
    "\n",
    "This progression allows you to:\n",
    "- Build intuition incrementally\n",
    "- Understand how each technique addresses limitations of previous ones\n",
    "- Develop a comprehensive toolkit for model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Evolution from Basic to Advanced Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Understanding *why* we need advanced models helps motivate the techniques covered in this course.\n",
    "\n",
    "\n",
    "\n",
    "### Limitations of Basic Logistic Regression\n",
    "\n",
    "In Course 2, you built logistic regression models that performed well but had certain limitations:\n",
    "\n",
    "1. **Linear decision boundaries**: Cannot capture complex, non-linear relationships\n",
    "2. **No automatic feature selection**: All features contribute to the prediction\n",
    "3. **Sensitivity to multicollinearity**: Correlated features can destabilize coefficient estimates\n",
    "4. **No interaction detection**: Manual feature engineering required for interactions\n",
    "\n",
    "\n",
    "\n",
    "### How Advanced Models Address These Limitations\n",
    "\n",
    "| Limitation | Solution | Covered In |\n",
    "|:-----------|:---------|:-----------|\n",
    "| Overfitting | Regularization (L1, L2, ElasticNet) | Module 1 |\n",
    "| Feature Selection | Lasso (L1) regularization | Module 1 |\n",
    "| Non-linearity | Decision Trees, Neural Networks | Modules 2, 5 |\n",
    "| Interactions | Tree-based models, Neural Networks | Modules 2-5 |\n",
    "| Variance | Ensemble methods (Random Forest) | Module 3 |\n",
    "| Bias | Boosting algorithms | Module 4 |\n",
    "| Complex patterns | Deep Neural Networks | Module 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual: Model Complexity Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a visual representation of model complexity\n",
    "models = ['Logistic\\nRegression', 'Regularized\\nLogistic', 'Decision\\nTree', \n",
    "          'Random\\nForest', 'Gradient\\nBoosting', 'Neural\\nNetwork']\n",
    "complexity = [1, 2, 3, 4, 5, 6]\n",
    "interpretability = [6, 5, 5, 3, 2, 1]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Complexity',\n",
    "    x=models,\n",
    "    y=complexity,\n",
    "    marker_color='steelblue'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Interpretability',\n",
    "    x=models,\n",
    "    y=interpretability,\n",
    "    marker_color='coral'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Complexity vs. Interpretability Trade-off',\n",
    "    barmode='group',\n",
    "    yaxis_title='Score (1-6)',\n",
    "    xaxis_title='Model Type',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above illustrates a fundamental trade-off in machine learning: as models become more complex and potentially more accurate, they often become less interpretable. Throughout this course, you will learn when to prioritize accuracy versus interpretability based on your specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Frequently Asked Questions (FAQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Do I need to complete Course 2 before starting Course 3?\n",
    "\n",
    ">Yes, Course 3 assumes familiarity with concepts covered in Course 2, including the ML cycle, data preprocessing, model evaluation metrics, and scikit-learn fundamentals. However, each module includes brief recaps of essential concepts.\n",
    "\n",
    "\n",
    "#### 2. Will these advanced models always outperform logistic regression?\n",
    "\n",
    ">Not necessarily. More complex models can achieve higher accuracy on some problems, but they also risk overfitting and are harder to interpret. Logistic regression often remains a strong baseline, especially with properly engineered features. Part of this course teaches you to evaluate this trade-off.\n",
    "\n",
    "\n",
    "#### 3. Do I need specialized hardware for neural networks?\n",
    "\n",
    ">For the neural networks covered in this course, Google Colab's free tier provides sufficient computational resources. We focus on foundational concepts using moderately-sized networks.\n",
    "\n",
    "\n",
    "#### 4. Which libraries will we use beyond scikit-learn?\n",
    "\n",
    ">In addition to scikit-learn, we will use:\n",
    ">- **XGBoost, LightGBM, CatBoost** for gradient boosting algorithms\n",
    ">- **TensorFlow/Keras or PyTorch** for neural networks\n",
    ">- **SHAP** for model interpretation\n",
    "\n",
    "\n",
    "#### 5. How much time should I allocate for this course?\n",
    "\n",
    ">Plan for **3-5 hours per week**. Advanced topics require more time for both understanding theory and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Recommended Approach\n",
    "\n",
    "1. **Complete modules in order**: Each module builds upon previous concepts\n",
    "2. **Run all code cells**: Experimentation is essential for learning\n",
    "3. **Compare results**: Track how each model performs on the same dataset\n",
    "4. **Take notes**: Document observations about model behavior and performance\n",
    "5. **Explore variations**: Modify hyperparameters and observe changes\n",
    "\n",
    "\n",
    "\n",
    "### Environment Setup\n",
    "\n",
    "Before proceeding, ensure your environment has the required packages installed. Run the cell below to install or upgrade necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Course 3\n",
    "!pip install -q xgboost lightgbm catboost shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installations\n",
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import catboost\n",
    "import shap\n",
    "\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "print(f\"XGBoost version: {xgboost.__version__}\")\n",
    "print(f\"LightGBM version: {lightgbm.__version__}\")\n",
    "print(f\"CatBoost version: {catboost.__version__}\")\n",
    "print(f\"SHAP version: {shap.__version__}\")\n",
    "print(\"\\nAll packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You are now ready to begin the technical content of Course 3. In **Module 1**, we start by extending logistic regression with regularization techniques that improve model performance and enable automatic feature selection.\n",
    "\n",
    "**Proceed to:** `1.1 Introduction to Regularization in Machine Learning`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
