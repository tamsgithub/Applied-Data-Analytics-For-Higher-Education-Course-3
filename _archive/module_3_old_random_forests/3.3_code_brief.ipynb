{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Code Brief: Train and Evaluate Random Forests\n",
    "\n",
    "Quick reference for training, evaluating, and analyzing random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filepath = '/content/drive/MyDrive/projects/Applied-Data-Analytics-For-Higher-Education-Course-2/'\n",
    "data_filepath = f'{root_filepath}data/'\n",
    "models_path = f'{root_filepath}course_3/models/'\n",
    "\n",
    "df_training = pd.read_csv(f'{data_filepath}training.csv')\n",
    "df_testing = pd.read_csv(f'{data_filepath}testing.csv')\n",
    "\n",
    "X_train, y_train = df_training, df_training['SEM_3_STATUS']\n",
    "X_test, y_test = df_testing, df_testing['SEM_3_STATUS']\n",
    "\n",
    "rf_baseline = pickle.load(open(f'{models_path}rf_baseline_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_baseline.fit(X_train, y_train)\n",
    "rf = rf_baseline.named_steps['classifier']\n",
    "\n",
    "print(f\"Number of trees: {rf.n_estimators}\")\n",
    "print(f\"OOB Score: {rf.oob_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {'accuracy': 'accuracy', 'precision': 'precision', 'recall': 'recall', 'f1': 'f1', 'roc_auc': 'roc_auc'}\n",
    "\n",
    "results = cross_validate(rf_baseline, X_train, y_train, cv=cv, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "    print(f\"  {metric}: {results[f'test_{metric}'].mean():.4f} (+/- {results[f'test_{metric}'].std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = rf_baseline.named_steps['preprocessing']\n",
    "minmax_features = preprocessor.transformers_[0][2]\n",
    "standard_features = preprocessor.transformers_[1][2]\n",
    "onehot_features = list(preprocessor.transformers_[2][1].get_feature_names_out(preprocessor.transformers_[2][2]))\n",
    "all_feature_names = list(minmax_features) + list(standard_features) + onehot_features\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Feature Importances:\")\n",
    "display(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_baseline.predict(X_test)\n",
    "y_prob = rf_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Test F1: {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Test ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_baseline, open(f'{models_path}rf_best_trained_model.pkl', 'wb'))\n",
    "print(\"Saved trained model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
