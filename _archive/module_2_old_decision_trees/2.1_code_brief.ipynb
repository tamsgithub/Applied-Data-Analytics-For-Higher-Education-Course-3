{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Code Brief: Introduction to Decision Trees\n",
    "\n",
    "Quick reference for decision tree concepts and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Impurity Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(0, 1, 100)\n",
    "gini = 1 - p**2 - (1-p)**2\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p, y=gini, mode='lines', line=dict(color='blue', width=3), name='Gini Impurity'))\n",
    "fig.add_trace(go.Scatter(x=[0, 0.5, 1], y=[0, 0.5, 0], mode='markers', marker=dict(size=12, color='red'),\n",
    "                         text=['Pure (all E)', 'Max Impurity', 'Pure (all N)'], textposition='top center'))\n",
    "fig.update_layout(title='Gini Impurity vs. Class Proportion', xaxis_title='Proportion of Class N', yaxis_title='Gini Impurity', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini vs Entropy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(0.001, 0.999, 100)\n",
    "gini = 1 - p**2 - (1-p)**2\n",
    "entropy = -p * np.log2(p) - (1-p) * np.log2(1-p)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=p, y=gini, mode='lines', line=dict(color='blue', width=3), name='Gini Impurity'))\n",
    "fig.add_trace(go.Scatter(x=p, y=entropy, mode='lines', line=dict(color='orange', width=3), name='Entropy'))\n",
    "fig.update_layout(title='Gini Impurity vs. Entropy', xaxis_title='Proportion of Class N', yaxis_title='Impurity Measure', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Split Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = pd.DataFrame({\n",
    "    'GPA': [3.5, 2.8, 1.9, 3.2, 2.1, 3.8, 2.5, 1.5],\n",
    "    'DFW_Rate': [0.0, 0.2, 0.5, 0.1, 0.4, 0.0, 0.3, 0.6],\n",
    "    'Enrolled': ['E', 'E', 'N', 'E', 'N', 'E', 'E', 'N']\n",
    "})\n",
    "\n",
    "p_enrolled = (sample_data['Enrolled'] == 'E').mean()\n",
    "gini_original = 1 - p_enrolled**2 - (1-p_enrolled)**2\n",
    "print(f\"Original Gini Impurity: {gini_original:.3f}\")\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree vs Logistic Regression Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X1_class0 = np.random.multivariate_normal([3, 0.15], [[0.3, 0], [0, 0.01]], n_samples//2)\n",
    "X1_class1 = np.random.multivariate_normal([2, 0.35], [[0.5, 0], [0, 0.015]], n_samples//2)\n",
    "X_demo = np.vstack([X1_class0, X1_class1])\n",
    "y_demo = np.array([0]*100 + [1]*100)\n",
    "X_demo[:, 0] = np.clip(X_demo[:, 0], 0, 4)\n",
    "X_demo[:, 1] = np.clip(X_demo[:, 1], 0, 1)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, random_state=42).fit(X_demo, y_demo)\n",
    "lr = LogisticRegression(random_state=42).fit(X_demo, y_demo)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0, 4, 100), np.linspace(0, 0.7, 100))\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z_dt = dt.predict_proba(mesh_points)[:, 1].reshape(xx.shape)\n",
    "Z_lr = lr.predict_proba(mesh_points)[:, 1].reshape(xx.shape)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Decision Tree', 'Logistic Regression'))\n",
    "for col, Z in enumerate([Z_dt, Z_lr], 1):\n",
    "    fig.add_trace(go.Contour(x=np.linspace(0, 4, 100), y=np.linspace(0, 0.7, 100), z=Z, colorscale='RdBu', showscale=False, opacity=0.6), row=1, col=col)\n",
    "    fig.add_trace(go.Scatter(x=X_demo[y_demo==0, 0], y=X_demo[y_demo==0, 1], mode='markers', marker=dict(color='blue', size=6), showlegend=(col==1), name='Enrolled'), row=1, col=col)\n",
    "    fig.add_trace(go.Scatter(x=X_demo[y_demo==1, 0], y=X_demo[y_demo==1, 1], mode='markers', marker=dict(color='red', size=6), showlegend=(col==1), name='Not Enrolled'), row=1, col=col)\n",
    "fig.update_layout(height=400, title_text='Decision Boundaries Comparison')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|:--------|:------------|\n",
    "| Gini Impurity | Probability of misclassification; 0 = pure |\n",
    "| Entropy | Information uncertainty; 0 = pure |\n",
    "| max_depth | Controls tree complexity |\n",
    "| Overfitting | Trees without constraints memorize data |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
