{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Build XGBoost Models - Code Brief\n",
    "\n",
    "Condensed reference for building XGBoost classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Build XGBoost classifier\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_encoded, y_train)\n",
    "y_pred = xgb_model.predict(X_test_encoded)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_encoded)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class imbalance ratio\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb_weighted = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "xgb_weighted.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "numerical_transformer = Pipeline([('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline([('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Full pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred = xgb_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_accuracy = cross_val_score(xgb_pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "cv_roc_auc = cross_val_score(xgb_pipeline, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print(f\"CV Accuracy: {cv_accuracy.mean():.3f} (+/- {cv_accuracy.std():.3f})\")\n",
    "print(f\"CV ROC-AUC: {cv_roc_auc.mean():.3f} (+/- {cv_roc_auc.std():.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Different importance types\n",
    "booster = xgb_model.get_booster()\n",
    "weight_scores = booster.get_score(importance_type='weight')\n",
    "gain_scores = booster.get_score(importance_type='gain')\n",
    "cover_scores = booster.get_score(importance_type='cover')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Parameters\n",
    "\n",
    "| Parameter | Description | Typical Range |\n",
    "|:----------|:------------|:--------------|\n",
    "| n_estimators | Number of trees | 100-1000 |\n",
    "| max_depth | Tree depth | 3-10 |\n",
    "| learning_rate | Step size | 0.01-0.3 |\n",
    "| subsample | Row sampling | 0.5-1.0 |\n",
    "| colsample_bytree | Column sampling | 0.5-1.0 |\n",
    "| scale_pos_weight | Class balance | 1 or neg/pos ratio |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
