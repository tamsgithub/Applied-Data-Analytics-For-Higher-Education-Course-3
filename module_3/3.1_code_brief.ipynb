{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Code Brief: Introduction to Ensemble Learning and Random Forests\n",
    "\n",
    "Quick reference for ensemble learning and random forest concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisdom of Crowds Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "true_value = 500\n",
    "n_guessers = 100\n",
    "individual_guesses = np.random.normal(true_value, 100, n_guessers)\n",
    "ensemble_averages = np.cumsum(individual_guesses) / np.arange(1, n_guessers + 1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, n_guessers + 1), y=individual_guesses, mode='markers',\n",
    "                         name='Individual Guesses', marker=dict(color='lightblue', size=6, opacity=0.6)))\n",
    "fig.add_trace(go.Scatter(x=np.arange(1, n_guessers + 1), y=ensemble_averages, mode='lines',\n",
    "                         name='Ensemble Average', line=dict(color='darkblue', width=3)))\n",
    "fig.add_hline(y=true_value, line_dash=\"dash\", line_color=\"red\", annotation_text=\"True Value\")\n",
    "fig.update_layout(title='Wisdom of Crowds: Ensemble Averaging', xaxis_title='Number of Models', yaxis_title='Prediction', height=450)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Sampling Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "original_data = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'])\n",
    "n_samples = len(original_data)\n",
    "\n",
    "print(\"Original Dataset:\", list(original_data))\n",
    "print(\"\\nBootstrap Samples:\")\n",
    "for i in range(3):\n",
    "    bootstrap_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    bootstrap_sample = original_data[bootstrap_indices]\n",
    "    oob_indices = set(range(n_samples)) - set(bootstrap_indices)\n",
    "    print(f\"Sample {i+1}: {list(bootstrap_sample)} | OOB: {list(original_data[list(oob_indices)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Reduction with Ensemble Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_experiments = 100\n",
    "tree_counts = [1, 5, 10, 25, 50, 100, 200]\n",
    "true_prob = 0.3\n",
    "\n",
    "variance_by_count = []\n",
    "for n_trees in tree_counts:\n",
    "    ensemble_predictions = []\n",
    "    for _ in range(n_experiments):\n",
    "        tree_preds = np.clip(np.random.normal(true_prob, 0.15, n_trees), 0, 1)\n",
    "        ensemble_predictions.append(np.mean(tree_preds))\n",
    "    variance_by_count.append(np.var(ensemble_predictions))\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tree_counts, y=variance_by_count, mode='lines+markers',\n",
    "                         line=dict(color='darkblue', width=3), marker=dict(size=10)))\n",
    "fig.update_layout(title='Variance Reduction with Ensemble Size', xaxis_title='Number of Trees',\n",
    "                  yaxis_title='Variance of Predictions', xaxis_type='log', height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|:--------|:------------|\n",
    "| Ensemble | Combine many weak learners into one strong learner |\n",
    "| Bagging | Parallel training on bootstrap samples |\n",
    "| Out-of-Bag (OOB) | ~37% of data not in each bootstrap sample |\n",
    "| Feature Randomness | Consider only subset of features at each split |\n",
    "| max_features | Typically sqrt(p) for classification |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
