{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6.1 Systematic Model Comparison Framework - Code Brief\n",
        "\n",
        "Condensed reference for comparing all model families."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, precision_recall_curve, average_precision_score,\n",
        "    brier_score_loss, log_loss\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary to store models and results\n",
        "models = {}\n",
        "training_times = {}\n",
        "\n",
        "# Logistic Regression (L2)\n",
        "models['Logistic Regression (L2)'] = LogisticRegression(\n",
        "    penalty='l2', C=0.1, solver='lbfgs', max_iter=1000, random_state=42\n",
        ")\n",
        "\n",
        "# Decision Tree\n",
        "models['Decision Tree'] = DecisionTreeClassifier(\n",
        "    max_depth=8, min_samples_split=20, min_samples_leaf=10,\n",
        "    class_weight='balanced', random_state=42\n",
        ")\n",
        "\n",
        "# Random Forest\n",
        "models['Random Forest'] = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=12, min_samples_split=10,\n",
        "    class_weight='balanced', n_jobs=-1, random_state=42\n",
        ")\n",
        "\n",
        "# Gradient Boosting\n",
        "models['Gradient Boosting'] = GradientBoostingClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=5, random_state=42\n",
        ")\n",
        "\n",
        "# XGBoost\n",
        "models['XGBoost'] = XGBClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=5,\n",
        "    eval_metric='logloss', random_state=42\n",
        ")\n",
        "\n",
        "# LightGBM\n",
        "models['LightGBM'] = LGBMClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=5,\n",
        "    class_weight='balanced', random_state=42, verbose=-1\n",
        ")\n",
        "\n",
        "# Neural Network\n",
        "models['Neural Network'] = MLPClassifier(\n",
        "    hidden_layer_sizes=(64, 32, 16), activation='relu', solver='adam',\n",
        "    alpha=0.001, max_iter=500, early_stopping=True, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models that require scaled features\n",
        "scaling_required = {\n",
        "    'Logistic Regression (L2)': True,\n",
        "    'Decision Tree': False,\n",
        "    'Random Forest': False,\n",
        "    'Gradient Boosting': False,\n",
        "    'XGBoost': False,\n",
        "    'LightGBM': False,\n",
        "    'Neural Network': True\n",
        "}\n",
        "\n",
        "# Train each model\n",
        "for model_name, model in models.items():\n",
        "    start_time = time.time()\n",
        "    if scaling_required.get(model_name, False):\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "    training_times[model_name] = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name, requires_scaling=False, X_test_scaled=None):\n",
        "    X_eval = X_test_scaled if requires_scaling else X_test\n",
        "    \n",
        "    y_pred = model.predict(X_eval)\n",
        "    y_prob = model.predict_proba(X_eval)[:, 1]\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1 Score': f1_score(y_test, y_pred),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_prob),\n",
        "        'Avg Precision': average_precision_score(y_test, y_prob)\n",
        "    }, y_pred, y_prob\n",
        "\n",
        "# Evaluate all models\n",
        "all_results = []\n",
        "probabilities = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    requires_scaling = scaling_required.get(model_name, False)\n",
        "    metrics, y_pred, y_prob = evaluate_model(\n",
        "        model, X_test, y_test, model_name,\n",
        "        requires_scaling=requires_scaling,\n",
        "        X_test_scaled=X_test_scaled\n",
        "    )\n",
        "    all_results.append(metrics)\n",
        "    probabilities[model_name] = y_prob\n",
        "\n",
        "results_df = pd.DataFrame(all_results).set_index('Model')\n",
        "results_df['Training Time (s)'] = results_df.index.map(training_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROC Curve Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get ROC curves for all models\n",
        "roc_curves = {}\n",
        "for model_name, y_prob in probabilities.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    roc_curves[model_name] = {'fpr': fpr, 'tpr': tpr, 'auc': auc}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Selection Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rank models by AUC\n",
        "ranked_df = results_df.sort_values('ROC-AUC', ascending=False)\n",
        "\n",
        "# Best model by different criteria\n",
        "print(f\"Best ROC-AUC: {results_df['ROC-AUC'].idxmax()}\")\n",
        "print(f\"Best F1 Score: {results_df['F1 Score'].idxmax()}\")\n",
        "print(f\"Best Recall: {results_df['Recall'].idxmax()}\")\n",
        "print(f\"Fastest Training: {min(training_times, key=training_times.get)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Concepts\n",
        "\n",
        "| Model | Interpretability | Best For |\n",
        "|:------|:-----------------|:---------|\n",
        "| Logistic Regression | High | Compliance, reports |\n",
        "| Decision Tree | Very High | Advisor tools |\n",
        "| Random Forest | Medium | Balanced needs |\n",
        "| Gradient Boosting | Low | Max performance |\n",
        "| Neural Network | Low | Complex patterns |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
